#!/bin/bash
# Data Platform Test Suite

CLUSTER_NAME="data-platform"
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "üß™ Testing Data Platform Components..."
echo "======================================"

# Function to check if a pod is ready
check_pods() {
    local namespace=$1
    local label=$2
    local name=$3
    
    echo -n "Checking $name... "
    if kubectl get pods -n $namespace -l $label 2>/dev/null | grep -q "Running"; then
        echo -e "${GREEN}‚úì Running${NC}"
        return 0
    else
        echo -e "${RED}‚úó Not Running${NC}"
        return 1
    fi
}

# 1. Check Cluster
echo ""
echo "1Ô∏è‚É£  Cluster Status"
echo "-------------------"
if kind get clusters | grep -q "$CLUSTER_NAME"; then
    echo -e "${GREEN}‚úì Kind cluster '$CLUSTER_NAME' exists${NC}"
else
    echo -e "${RED}‚úó Cluster not found${NC}"
    exit 1
fi

# 2. Check All Pods
echo ""
echo "2Ô∏è‚É£  Pod Health Check"
echo "-------------------"
check_pods "default" "app.kubernetes.io/name=postgresql" "PostgreSQL"
check_pods "default" "app=minio" "MinIO"
check_pods "default" "app=kafka" "Kafka"
check_pods "airflow" "component=scheduler" "Airflow Scheduler"
check_pods "airflow" "tier=airflow" "Airflow API Server"
check_pods "spark-operator" "app.kubernetes.io/name=spark-operator" "Spark Operator"
check_pods "default" "app=lakekeeper" "Lakekeeper (Iceberg REST)"
check_pods "default" "app=trino" "Trino Query Engine"
check_pods "default" "app=hive-metastore" "Hive Metastore"

# 3. Test PostgreSQL
echo ""
echo "3Ô∏è‚É£  PostgreSQL Connection Test"
echo "-----------------------------"
POSTGRES_POD=$(kubectl get pod -l app.kubernetes.io/name=postgresql -o jsonpath="{.items[0].metadata.name}")
POSTGRES_PASSWORD=$(kubectl get secret postgres-postgresql -o jsonpath="{.data.postgres-password}" | base64 -d)

if kubectl exec $POSTGRES_POD -- env PGPASSWORD=$POSTGRES_PASSWORD psql -U postgres -c "SELECT version();" > /dev/null 2>&1; then
    echo -e "${GREEN}‚úì PostgreSQL connection successful${NC}"
    POSTGRES_VERSION=$(kubectl exec $POSTGRES_POD -- env PGPASSWORD=$POSTGRES_PASSWORD psql -U postgres -t -c "SELECT version();" | head -n1 | xargs)
    echo "  Version: $POSTGRES_VERSION"
    
    # Check PostGIS
    POSTGIS_VERSION=$(kubectl exec $POSTGRES_POD -- env PGPASSWORD=$POSTGRES_PASSWORD psql -U postgres -t -c "SELECT PostGIS_Version();" 2>/dev/null | xargs)
    if [ ! -z "$POSTGIS_VERSION" ]; then
        echo -e "  ${GREEN}‚úì PostGIS enabled: $POSTGIS_VERSION${NC}"
        
        # Check PostGIS extensions
        EXTENSIONS=$(kubectl exec $POSTGRES_POD -- env PGPASSWORD=$POSTGRES_PASSWORD psql -U postgres -t -c "SELECT COUNT(*) FROM pg_extension WHERE extname LIKE 'postgis%';" 2>/dev/null | xargs)
        echo "  PostGIS extensions loaded: $EXTENSIONS"
    else
        echo -e "  ${YELLOW}‚ö† PostGIS not enabled${NC}"
    fi
else
    echo -e "${RED}‚úó PostgreSQL connection failed${NC}"
fi

# 4. Test MinIO
echo ""
echo "4Ô∏è‚É£  MinIO Object Storage Test"
echo "----------------------------"
MINIO_POD=$(kubectl get pod -l app=minio -o jsonpath="{.items[0].metadata.name}")
if kubectl exec $MINIO_POD -- curl -f http://localhost:9000/minio/health/live > /dev/null 2>&1; then
    echo -e "${GREEN}‚úì MinIO connection successful${NC}"
    echo "  API: minio.default.svc.cluster.local:9000"
    echo "  Console: Use 'kubectl port-forward svc/minio 9001:9001'"
else
    echo -e "${RED}‚úó MinIO connection failed${NC}"
fi

# 5. Test Kafka
echo ""
echo "5Ô∏è‚É£  Kafka Message Broker Test"
echo "----------------------------"
KAFKA_POD=$(kubectl get pod -l app=kafka -o jsonpath="{.items[0].metadata.name}")
if kubectl exec $KAFKA_POD -- /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092 > /dev/null 2>&1; then
    echo -e "${GREEN}‚úì Kafka connection successful${NC}"
    
    # Create test topic
    kubectl exec $KAFKA_POD -- /opt/kafka/bin/kafka-topics.sh --create --topic test-topic \
        --bootstrap-server localhost:9092 --if-not-exists --partitions 1 --replication-factor 1 > /dev/null 2>&1
    
    # List topics
    TOPIC_COUNT=$(kubectl exec $KAFKA_POD -- /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092 2>/dev/null | wc -l)
    echo "  Total topics: $TOPIC_COUNT"
    
    # Test produce/consume
    echo "test-message-$(date +%s)" | kubectl exec -i $KAFKA_POD -- /opt/kafka/bin/kafka-console-producer.sh \
        --broker-list localhost:9092 --topic test-topic > /dev/null 2>&1
    
    MESSAGE=$(kubectl exec $KAFKA_POD -- /opt/kafka/bin/kafka-console-consumer.sh \
        --bootstrap-server localhost:9092 --topic test-topic --from-beginning --max-messages 1 --timeout-ms 5000 2>/dev/null)
    
    if [ ! -z "$MESSAGE" ]; then
        echo -e "${GREEN}‚úì Message produce/consume successful${NC}"
    fi
else
    echo -e "${RED}‚úó Kafka connection failed${NC}"
fi

# 6. Test Airflow
echo ""
echo "6Ô∏è‚É£  Airflow Orchestrator Test"
echo "----------------------------"
SCHEDULER_POD=$(kubectl get pod -n airflow -l component=scheduler -o jsonpath="{.items[0].metadata.name}")
if kubectl exec -n airflow $SCHEDULER_POD -- airflow version > /dev/null 2>&1; then
    AIRFLOW_VERSION=$(kubectl exec -n airflow $SCHEDULER_POD -- airflow version 2>/dev/null)
    echo -e "${GREEN}‚úì Airflow is operational${NC}"
    echo "  Version: $AIRFLOW_VERSION"
    
    # List DAGs
    DAG_COUNT=$(kubectl exec -n airflow $SCHEDULER_POD -- airflow dags list 2>/dev/null | grep -v "dag_id" | grep -v "^$" | wc -l)
    echo "  Total DAGs: $DAG_COUNT"
else
    echo -e "${RED}‚úó Airflow connection failed${NC}"
fi

# 7. Test Spark Operator
echo ""
echo "7Ô∏è‚É£  Spark Operator Test"
echo "----------------------"
if kubectl get crd sparkapplications.sparkoperator.k8s.io > /dev/null 2>&1; then
    echo -e "${GREEN}‚úì Spark Operator CRDs installed${NC}"
    SPARK_APP_COUNT=$(kubectl get sparkapplications --all-namespaces 2>/dev/null | grep -v "NAME" | wc -l)
    echo "  Running Spark applications: $SPARK_APP_COUNT"
else
    echo -e "${RED}‚úó Spark Operator CRDs not found${NC}"
fi

# 8. Test Lakekeeper
echo ""
echo "9Ô∏è‚É£  Lakekeeper REST Catalog Test"
echo "-------------------------------"
LAKEKEEPER_POD=$(kubectl get pod -l app=lakekeeper -o jsonpath="{.items[0].metadata.name}" 2>/dev/null)
if [ ! -z "$LAKEKEEPER_POD" ]; then
    if kubectl exec $LAKEKEEPER_POD -- curl -s http://localhost:8181/health > /dev/null 2>&1; then
        echo -e "${GREEN}‚úì Lakekeeper is operational${NC}"
        echo "  REST Catalog endpoint: http://lakekeeper.default.svc.cluster.local:8181"
    else
        echo -e "${RED}‚úó Lakekeeper health check failed${NC}"
    fi
else
    echo -e "${RED}‚úó Lakekeeper pod not found${NC}"
fi

# 9. Test Trino
echo ""
echo "8Ô∏è‚É£  Trino Query Engine Test"
echo "--------------------------"
TRINO_POD=$(kubectl get pod -l app=trino -o jsonpath="{.items[0].metadata.name}" 2>/dev/null)
if [ ! -z "$TRINO_POD" ]; then
    if kubectl exec $TRINO_POD -- curl -s http://localhost:8080/v1/info > /dev/null 2>&1; then
        echo -e "${GREEN}‚úì Trino is operational${NC}"
        TRINO_VERSION=$(kubectl exec $TRINO_POD -- curl -s http://localhost:8080/v1/info | grep -o '"version":"[^"]*"' | cut -d'"' -f4)
        echo "  Version: $TRINO_VERSION"
        
        # List catalogs
        echo "  Checking Iceberg catalog..."
        kubectl exec $TRINO_POD -- trino --execute "SHOW CATALOGS;" 2>/dev/null | grep -q "iceberg" && echo -e "  ${GREEN}‚úì Iceberg catalog available${NC}" || echo -e "  ${YELLOW}‚ö† Iceberg catalog not found${NC}"
    else
        echo -e "${RED}‚úó Trino connection failed${NC}"
    fi
else
echo -e "${YELLOW}Trino:${NC}"
echo "  kubectl port-forward svc/trino 8080:8080"
echo "  ‚Üí http://localhost:8080"
echo ""
echo -e "${YELLOW}Lakekeeper (Iceberg REST):${NC}"
echo "  kubectl port-forward svc/lakekeeper 8181:8181"
echo "  ‚Üí http://localhost:8181"
echo ""
    echo -e "${RED}‚úó Trino pod not found${NC}"
fi

# 10. Service URLs
echo ""
echo "8Ô∏è‚É£  Access Information"
echo "--------------------"
echo "To access services, run these port-forward commands:"
echo ""
echo -e "${YELLOW}Airflow UI:${NC}"
echo "  kubectl port-forward svc/airflow-api-server 8080:8080 -n airflow"
echo "  ‚Üí http://localhost:8080 (admin/admin)"
echo ""
echo -e "${YELLOW}MinIO Console:${NC}"
echo "  kubectl port-forward svc/minio 9001:9001"
echo "  ‚Üí http://localhost:9001 (admin/minio_password)"
echo ""
echo -e "${YELLOW}PostgreSQL:${NC}"
echo "  kubectl port-forward svc/postgres-postgresql 5432:5432"
echo "  ‚Üí localhost:5432 (postgres/<get-secret>)"
echo ""

# 9. Summary
echo ""
echo "‚úÖ Test Suite Complete!"
echo "======================"
echo ""
echo "Next steps:"
echo "1. Deploy your DAGs: kubectl cp dags/spark_orchestrator_dag.py airflow/$SCHEDULER_POD:/opt/airflow/dags/"
echo "2. Submit Spark jobs: kubectl apply -f manifests/sedona_job.yaml"
echo "3. Monitor with: kubectl get pods --all-namespaces -w"
